{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entropy and Decision Trees\n",
    "\n",
    "In this exercise we shall look at the concepts of 'entropy' and 'information gain' and how they can be employed in coding a 'decision tree', which can be used to classify samples.\n",
    "\n",
    "If you want to understand the extremely significant but enigmatic concept of 'entropy' I suggest the following:\n",
    "[The Science of Information: From Language to Black Holes, by Benjamin Schumacher](https://www.amazon.co.uk/Science-Information-Language-Black-Holes/dp/B07K8ZBG14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The data\n",
    "\n",
    "We shall apply the decision tree technique to the well known \n",
    "<a href=\"https://en.wikipedia.org/wiki/Iris_flower_data_set\">Iris flower dataset</a> that contains information about properties and classification of iris flowers. Briefly, there are three types of Iris flower. The dataset contains measurements for many individual flowers, along with a classification stating which of the three types of Iris each flower is. Our aim is to learn how the flower type can be predicted from the measurements given.  \n",
    "\n",
    "The Python library scikit-learn includes several datasets that you can practice with. You can read about the Iris dataset and others [here](https://scikit-learn.org/stable/datasets/toy_dataset.html#toy-datasets). The data provided is very clean so there is no extra work to do before we can start our analysis. That's really useful when learning a new technique but remember that when you come to use real data there is likely to be a significant amount of initial effort required to deal with missing or incomplete data, poor formatting and wrong datatypes etc.\n",
    "\n",
    "Let's begin by loading the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets   # load the sklearn datasets\n",
    "iris = datasets.load_iris()    # load the \"iris\" dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset that has been assigned to variable \"iris\" is a somewhat complex Python object. As well as arrays of numerical data that give measurements of a set of samples, it includes other information regarding the naming of the data, and the desired classification of the data into \"target\" classes.\n",
    "\n",
    "The most important attributes are described in the following table.\n",
    "\n",
    "|attribute name|description|\n",
    "| :---: | :--- |\n",
    "|data|the actual data|\n",
    "|target|the correct classification|\n",
    "|target_names|the names of each classification|\n",
    "|feature_names|names of the columns|\n",
    "|DESCR|a summary of the dataset object|\n",
    "\n",
    "The data and target are provided as numpy arrays.\n",
    "\n",
    "To see the full data structure, run the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is a numpy array by default, or a pandas dataframe if `as_frame=False` is passsed into the `load_iris()` function.\n",
    "Let us have a look at some of the data in the iris dataset.\n",
    "We can get the first 5 items of the data array by doing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.data[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These numbers correspond to the values of certain features. We can look at the feature names as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target classification is a single value (0, 1, or 2) for each item. \n",
    "The target_names array gives the meaning of these values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iris.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, for example, the first entry has target 0 so these measurements were from a flower of type 'setsoa'.\n",
    "The following function prints out all the relevant information for a single item of data in a nice readable format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_row(iris, i):\n",
    "    print(\"Data row {}\".format(i))\n",
    "    values = iris.data[i]\n",
    "    for feature_index, feature_name in enumerate(iris.feature_names):\n",
    "        print('{}: {}'.format(feature_name, values[feature_index]))\n",
    "    print('Target: {} (code {})'.format(iris.target_names[iris.target[i]], iris.target[i]))\n",
    "\n",
    "print_row(iris, 103)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision trees\n",
    "\n",
    "A **decision tree** is a classifier, which  decides the classification of entities based on a sequence of tests. In this example, we want to create a decision tree that will classify iris flowers into one of three types based on tests relating to the four measurements provided in the dataset.\n",
    "\n",
    "Scikit-learn offers a huge range of machine learning functionality, including a decision tree class and the ability to learn decision trees. In fact, we only need to write a few of lines of code! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# learn a decision tree \n",
    "clf = DecisionTreeClassifier().fit(iris.data, iris.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see what this has created we can use the built-in functionality to print out the decision tree.\n",
    "Spend some time studying the decision tree diagram that is printed out. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# display the decision tree\n",
    "plt.figure(figsize=(16,12))\n",
    "plot_tree(clf)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the diagram, each rectangle is a 'node' in the tree.\n",
    "Some nodes have arrows to two other nodes, these are called its 'children'. \n",
    "A node which has no outgoing arrows is called a 'leaf'.\n",
    "A non-leaf node in a decision tree represents a test that can be applied to a sample.\n",
    "\n",
    "The first line written at each non-leaf node describes the test associated with that node. For example, `X[2] <= 2.45` means the first node applies the test of whether the petal length measurement (feature 2 in our dataset) is less than or equal to 2.45cm. \n",
    "\n",
    "Consider the example piece of data \n",
    "```\n",
    "Data row 103\n",
    "sepal length (cm): 6.3\n",
    "sepal width (cm): 2.9\n",
    "petal length (cm): 5.6\n",
    "petal width (cm): 1.8\n",
    "Target: virginica (code 2)\n",
    "```\n",
    "We can use the tests in the tree to classify it. \n",
    "The petal length is not less than 2.45cm. \n",
    "Because the test from the first node is false in this case we should move to the right-hand child.\n",
    "In the case that the test was true we would have moved to the left-hand child. \n",
    "The test in the next node is `X[3] <= 1.75`. The petal width is not less than 1.75 for this sample so again we move to the right-hand child. \n",
    "Apply the test in this node, you should see that we move again to the right-hand child, which is a leaf node. \n",
    "Now there are no more tests to apply. \n",
    "\n",
    "The last line at each node shows the number of samples from the training data of each classification for which applying the tests as described would lead to this node.\n",
    "At the leaf nodes all the samples have the same classification.\n",
    "If a sample reaches this node we know that it belongs to this classification. \n",
    "\n",
    "The method `predict()` will apply the tests to a list of samples and return a list of classifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get the classification for sample 103\n",
    "clf.predict([iris.data[103]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, this sample was used in defining the decision tree and we already know its classification, so being able to 'predict' the classification isn't very useful! \n",
    "In general, as with any form of machine learning, we would aim to learn a model which can be applied to data that it hasn't been trained on. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rest of this lesson will show how to implement a simple decision tree learning algorithm yourself. \n",
    "It's often much easier and better to use well maintained packages like scikit-learn for machine learning rather than try to write your own from scratch. \n",
    "However, implementing your own algorithm, even though it might be imperfect, is one way to gain a deeper insight into the theoretical basis for a technique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Entropy Equation\n",
    "\n",
    "Before we can build a decision tree we need to understand the concept of entropy.\n",
    "Entropy is the average amount of information given by an event, when considering all possible outcomes.\n",
    "For example, a single flip of an unbiased coin gives one bit of information.\n",
    "The outcome can be represented by a single bit (a 0 or 1) and we have no reason to expect one outcome over the other so this one bit is giving us the maximum possible new information that it can. \n",
    "At the opposite extreme, the outcome of flipping a coin which always lands the same way can also be represented in a single bit of data, but because we already know what the outcome will be before looking that bit carries no new information. \n",
    "\n",
    "Another way to think about entropy is the amount of diversity in a dataset. \n",
    "If every value is the same then each individual data point gives no new information.\n",
    "So a collection of data points has lower entropy if most items belong to the same class (or to a small number of classes) and higer entropy if the data points show a great deal of variety and are more evenly split between the possible classes. \n",
    "\n",
    "More specifically, suppose we have a set of $N$ events (e.g. coin flips) that can be divided into $k$ classes (e.g. heads or tails) and the number of entities in class $i$ is $n_i$ (so $\\sum_{i=1}^k n_i = N$). Then the proportion $P_i$ of entities that are in class $i$\n",
    "is $\\frac{n_i}{N}$. \n",
    "\n",
    "The _entropy_ $S$ of this classification is given by the equation\n",
    "$$\n",
    "S= - \\sum_{i=1}^k P_i \\log_2 (P_i)\n",
    "$$\n",
    "\n",
    "We can also write this as:\n",
    "$$\n",
    "S= \\sum_{i=1}^k P_i \\log_2 \\left(\\frac{1}{P_i}\\right)\n",
    "$$\n",
    "\n",
    "Here the $\\log_2 \\left(\\frac{1}{P_i}\\right)$ term gives the average number of _bits_ that would be needed to specify that an entitiy lies within a $P_i$ sized portion of the set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell defines a function to calculate entropy from a list specifying how often multiple outcomes occur.\n",
    "We then use this function to calculate and plot the entropy for events in which there are two outcomes and the first happens $x$ times out of 100 for $x$ ranging in value from 0 to 100. \n",
    "As expected, an event where each outcome happens 50 times out of 100 has entropy 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def calculate_entropy_from_outcome_distribution(number_vector):\n",
    "    \"\"\"\n",
    "        Calculate entropy given a list of the number of outcomes in each category.\n",
    "        \n",
    "        Parameters:\n",
    "            number_vector list(ints): Numbers of outcomes for different categories.\n",
    "            \n",
    "        Returns:\n",
    "            A float representing the entropy of an event with distribution as number_vector\n",
    "            \n",
    "        len(number_vector) is the number of different possible outcomes.\n",
    "        number_vector[i] is the number of events with outcome i.\n",
    "        sum(number_vector) is the total number of events.\n",
    "        Therefore number_vector[i]/sum(number_vector) is the probability of outcome i.\n",
    "    \"\"\"\n",
    "    total = sum(number_vector) # N, total number of events \n",
    "    entropy = 0 # initialise\n",
    "    \n",
    "    for number in number_vector: # n_i, number of outcomes of type i\n",
    "        if number == 0:\n",
    "            continue # outcome did not occur, has no effect on entropy\n",
    "        proportion = number/total # P_i\n",
    "        entropy -= proportion * math.log(proportion, 2) # P_i * log_2(P_i)\n",
    "    \n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt  \n",
    "\n",
    "# list of tuples of the form (number of events with outcome A, number of events with outcome B)\n",
    "# with 100 total outcomes recorded\n",
    "xvals = [(x, 100-x) for x in range(0,101)] \n",
    "\n",
    "# Calculate entropy for each outcome possibility\n",
    "yvals = [calculate_entropy_from_outcome_distribution(outcome_tuple) for outcome_tuple in xvals]  \n",
    "\n",
    "# plot freq of outcome A vs entropy\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(xvals, yvals) \n",
    "\n",
    "ax.grid()\n",
    "ax.set_title('Entropy of events with exactly two outcomes')\n",
    "ax.set_xticks(range(0,101, 10))\n",
    "ax.set_xlabel('% of events with outcome A')\n",
    "ax.set_ylabel('Entropy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a  Decision Tree\n",
    "A simple binary decision tree can be defined by the following recursive definition:\n",
    "\n",
    "*    `DT => [Test, DT, DT]`\n",
    "*    `DT => C1 | ... | Cn`\n",
    "\n",
    "The first case corresponds to the application of a test to an entity. According to whether the test is positive or negative we get one of two decision trees, which can then be again applied to the entity. \n",
    "The second clause represents the end of the decision process, where we assign a class to the sample.\n",
    "\n",
    "The challenge when creating a decision tree is to find 'good' tests. \n",
    "We aim to use as few tests as possible to classify an entity.\n",
    "To decide which tests to use we take some training data and consider all the tests which could split the samples into two parts.\n",
    "Then we find the entropy of each part with respect to the classifications we want to recognise.\n",
    "If the entropy is low in a collection of samples then this means most of the samples belong to the same class.\n",
    "If both parts have low entropy that suggests the test was good at distinguishing between the different possible classes. \n",
    "We repeat this process until our training data has been split into collections which each contain entities belonging to a single class.\n",
    "\n",
    "We can now define functions to build a decision tree in this way and use it to classify a sample. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample object\n",
    "Sample objects will contain a set of properties and their classification.\n",
    "A nice structure that Python provides is a named tuple.\n",
    "This is just a tuple in which each item can be referenced by a name as well as its index, which can make code a bit more readable.\n",
    "It's a lightweight alternative to a very simple class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple \n",
    "\n",
    "Sample = namedtuple('Sample', ['properties', 'class_index'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create a sample object for each record in the iris data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_samples = [Sample(iris.data[i], iris.target[i]) for i in range(len(iris.data))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(iris_samples[103].properties)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests to split the training dataset\n",
    "First we need to define all possible tests. \n",
    "In this dataset we have data collected across four properties for 150 samples. \n",
    "We will define tests for each of the four properties.\n",
    "All properties have numerical data values so the natural question to ask about a given sample is whether the value for a property is greater than or less than some number $x$.\n",
    "The choices of $x$ can be restricted to the values which appear in the dataset for this property.\n",
    "\n",
    "If we had categorical data instead then it would not make sense to ask if a value is greater than or less than another value. \n",
    "For example, we may consider the color of each sample. \n",
    "In this case a slightly different type of test is required, but it is not hard to generalise the ideas from numerical to categorical data types.\n",
    "\n",
    "We will create a test for each of the (up to) 150 values for each property.\n",
    "The test can be expressed simply as the property which is being considered and the value of $x$ which will be used to split the data set into those samples which have a value less than or equal to $x$ for this property and those which have a value greater than $x$ for this property.\n",
    "\n",
    "The function is defined so that if two identical tests are created only one copy is kept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NumericTest = namedtuple('NumericTest', ['property_index', 'value'])\n",
    "\n",
    "def get_numeric_tests_from_samples(samples):\n",
    "    \"\"\"\n",
    "        Define a test for each property of each sample.\n",
    "        The test contains the property index and the value of this property for this sample.\n",
    "        the idea is that we will later use these property values \n",
    "        to find a value that partitions the set of samples in a 'good' way \n",
    "        \n",
    "        Parameters:\n",
    "            samples: a list of objects of class Sample\n",
    "            \n",
    "        Returns:\n",
    "            list of NumericTest tuples (property_index, value)\n",
    "    \"\"\"\n",
    "    tests = set()\n",
    "    for s in samples:\n",
    "        for property_index, value in enumerate(s.properties):\n",
    "            tests.add(NumericTest(property_index, value))\n",
    "    return list(tests)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to decide which test is the best at splitting our dataset we need to look at how the test splits the training dataset.\n",
    "The next function simply applies a test to a set of samples and returns the two resulting subsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_samples_by_numeric_test(samples, test):\n",
    "    \"\"\"\n",
    "        A test is a property index and value.\n",
    "        We will test whether the relevant property is greater than the specified value \n",
    "        for each sample in samples.\n",
    "        \n",
    "        Parameters:\n",
    "            samples: a list of objects of class Sample\n",
    "            test: a NumericTest tuple (property_index, value).\n",
    "            \n",
    "        Returns:\n",
    "            tuple of (leq_samples, gt_samples)\n",
    "            where leq_samples: number of samples with relevant property not greater than the value given in test\n",
    "            and gt_samples: number of samples with relevant property greater than the value given in test\n",
    "    \"\"\"\n",
    "    leq_samples = []\n",
    "    gt_samples = []\n",
    "    for s in samples:\n",
    "        if s.properties[test.property_index] > test.value:\n",
    "            gt_samples.append(s)\n",
    "        else:\n",
    "            leq_samples.append(s)\n",
    "    return leq_samples, gt_samples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell is just an example of how these functions can be used. \n",
    "We get all of the tests appropriate for the iris dataset, and for the first of these check how it splits the data into two sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tests = get_numeric_tests_from_samples(iris_samples) \n",
    "example_test =  all_tests[0]\n",
    "\n",
    "leq_samples, gt_samples = split_samples_by_numeric_test(iris_samples, example_test)\n",
    "\n",
    "split_nums = (len(leq_samples), len(gt_samples))\n",
    "split_nums"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating tests\n",
    "\n",
    "The purpose of a decision tree is to split the data into subsets, each of which belong to the same classification. \n",
    "So to decide whether a test is 'good' we will look at the two subsets resulting from applying that test to our training data, in particular considering the classification that each sample belongs to.\n",
    "Ideally we would like the subsets to each contain samples which all have the same classification. \n",
    "More generally we would like the subsets to show little variety with respect to the classification of the samples. \n",
    "The precise way to measure this is to calculate the entropy of the two sets of samples that result from applying a test. \n",
    "\n",
    "The next function calculates the entropy of a set of samples.\n",
    "We will use this to calculate the average of the entropy of the two subsets resulting from a test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_frequency(samples):\n",
    "    \"\"\"\n",
    "        Count the number of samples of each classification\n",
    "        \n",
    "        Parameters:\n",
    "            samples: list of Sample objects\n",
    "        \n",
    "        Returns:\n",
    "            dict {class_index: frequency} \n",
    "    \"\"\"\n",
    "    freq_dict = {}\n",
    "    \n",
    "    for s in samples:\n",
    "        if s.class_index in freq_dict:\n",
    "            freq_dict[s.class_index] += 1\n",
    "        else:\n",
    "            freq_dict[s.class_index] = 1\n",
    "    \n",
    "    return freq_dict\n",
    "\n",
    "def classification_entropy(samples):\n",
    "    \"\"\"\n",
    "        Given a list of Sample objects, group according to classification and get entropy of the distribution.\n",
    "        \n",
    "        Parameters:\n",
    "            samples: list of Sample objects\n",
    "        \n",
    "        Returns:\n",
    "            float, classification entropy of samples\n",
    "    \"\"\"\n",
    "    freq_dict = classification_frequency(samples)\n",
    "    freq_list = freq_dict.values()\n",
    "    return calculate_entropy_from_outcome_distribution(freq_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classification_entropy(iris_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next task is to consider the entropy from both subsets of samples following a test.\n",
    "We average the two entropy values so that larger sample sets have more weight -- it is not helpful to have one very small set of samples with low entropy if the other much larger set has a high entropy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_classification_entropy_after_test(samples, test):\n",
    "    \"\"\"\n",
    "        Apply the given test to the samples\n",
    "        Calculate the entropy of both resulting sets of samples\n",
    "        and return the average of these.\n",
    "        \n",
    "        Parameters:\n",
    "            samples: a list of Samples\n",
    "            test: a NumericTest tuple\n",
    "            \n",
    "        Return:\n",
    "            float, the average entropy after applying the test\n",
    "    \"\"\"\n",
    "    leq, gt = split_samples_by_numeric_test(samples, test)\n",
    "    num_leq = len(leq)\n",
    "    num_gt = len(gt)\n",
    "    expected = ((num_leq/(num_leq+num_gt)) * classification_entropy(leq)\n",
    "                 +\n",
    "                 (num_gt/(num_leq+num_gt)) * classification_entropy(gt))\n",
    "    return expected        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a method to calculate the average entropy following a test we can decide which test is most promising for our classification problem.\n",
    "\n",
    "In the following function we make use of the expression `min(test_results, key = lambda x : x[1])`.\n",
    "`test_results` is a list of tuples and there is no default ordering for tuples. Therefore the `key` parameter is provided to tell Python how to sort the tuples.\n",
    "\n",
    "A `lambda` is an anonymous function.\n",
    "```\n",
    "lambda x : x[1]\n",
    "```\n",
    "is equivalent to  \n",
    "``` \n",
    "def my_function(x):\n",
    "        return x[1]\n",
    "```\n",
    "except that in the latter case the function has the name `my_function`.\n",
    "\n",
    "Overall the expression `min(test_results, key = lambda x : x[1])` says to find the \"minimum\" valued tuple, where the value of each tuple is assumed to be the value it contains in position 1 (which is a numerical value, and therefore has a default ordering)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_test_and_result(samples):\n",
    "    \"\"\"\n",
    "        Get all tests based on the set of samples\n",
    "        Determine the best test based on average entropy after applying it\n",
    "        to these samples\n",
    "        \n",
    "        Parameters:\n",
    "            samples: a list of Samples\n",
    "            \n",
    "        Returns:\n",
    "            (NumericTest, average entropy)\n",
    "    \"\"\"\n",
    "    tests = get_numeric_tests_from_samples(samples)\n",
    "    ceat = average_classification_entropy_after_test\n",
    "    test_results = [(test, ceat(samples, test)) for test in tests]\n",
    "    \n",
    "    # get the test with the best (ie lowest entropy) result\n",
    "    # because we are sorting tuples we provide a rule for the sorting (key)\n",
    "    # in this case we sort the tuples according to the value in position 1.\n",
    "    best = min(test_results, key = lambda x : x[1])\n",
    "    \n",
    "    # return the test and result pair\n",
    "    return best "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that there may be several tests with the same average entropy, our function does not explicitly state how this should be handled. Does it matter? What could be changed to make the choice explicit in the case of a tie in average entropy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_best_test_and_result(iris_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning a decision tree\n",
    "Now we have all the ingredients we need to create a decision tree from a set of training data. \n",
    "We will generate tests and find the average entropy of the two sample subsets resulting from each test. \n",
    "The test with the lowest associated average entropy is the best test at this point, so we split the samples accordingly and create another decision tree for each of the new sample sets. \n",
    "\n",
    "The process continues until we have a sample set containing all samples of the same type.\n",
    "Alternatively, we stop generating further decision trees if there is no test which results in a lower entropy than the orignial sample set has. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_decision_tree(samples):\n",
    "    \"\"\"\n",
    "        learn a decision tree from a set of training samples\n",
    "        \n",
    "        Parameters:\n",
    "            samples: a list of Samples, the training data\n",
    "            \n",
    "        Return:\n",
    "            a decision tree [test, left_tree, right_tree]\n",
    "    \"\"\"\n",
    "    if samples == []:\n",
    "        return \"No Samples\"\n",
    "    \n",
    "    sample_classes = classification_frequency(samples)\n",
    "    \n",
    "    # Check if all samples are in one class. Then we are done.\n",
    "    if len(sample_classes) <= 1:\n",
    "        return [\"Classified\", sample_classes]\n",
    "    \n",
    "    initial_entropy = classification_entropy(samples)\n",
    "    test, entropy = find_best_test_and_result(samples)\n",
    "    \n",
    "    if entropy == initial_entropy:\n",
    "        return [\"Mixed\", sample_classes]\n",
    "    leq, gt = split_samples_by_numeric_test(samples,test)\n",
    "    \n",
    "    # Make decision trees for samples remaining after each of\n",
    "    # the test outcomes (<= and >)\n",
    "    left_tree = make_decision_tree(leq)\n",
    "    right_tree = make_decision_tree(gt)\n",
    "    return [test, left_tree, right_tree]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def display_decision_tree(dt, class_names, property_names, prefix='', indent=0):\n",
    "    \"\"\"\n",
    "        print a decision tree in a readable way.\n",
    "        \n",
    "        Parameters:\n",
    "            dt: the tree to be printed\n",
    "            class_names: names of target classes for the data used to train dt\n",
    "            property_names: names of properties for the data used to train dt\n",
    "            prefix: a strong to be printed before the tree\n",
    "            indent: amount of indentation before printing the tree\n",
    "        \n",
    "        Returns:\n",
    "            None\n",
    "    \"\"\"\n",
    "    print(\" \"*6*indent, prefix, end='')\n",
    "    if len(dt) < 3:\n",
    "        classification = [class_names[k]+' ({})'.format(v) for k,v in dt[1].items()]\n",
    "        print(dt[0], ','.join(classification))\n",
    "    else:\n",
    "        test = dt[0]\n",
    "        print( \"test:\", property_names[test[0]], test[1])\n",
    "        display_decision_tree(dt[1], class_names, property_names, 'leq - ', indent+1)\n",
    "        display_decision_tree(dt[2], class_names, property_names, 'gt - ', indent+1)       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We make a decision tree for the iris data.\n",
    "We will first remove one sample of each class to test the decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = []\n",
    "training_set = []\n",
    "class_indices = []\n",
    "\n",
    "for i, s in enumerate(iris_samples):\n",
    "    if s.class_index not in class_indices:\n",
    "        test_set.append(s)\n",
    "        class_indices.append(s.class_index)\n",
    "    else:\n",
    "        training_set.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = make_decision_tree(training_set)\n",
    "display_decision_tree(dt, iris.target_names, iris.feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the decision tree\n",
    "Now we want to use the decision tree to classify our three testing samples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_with_decision_tree(tree, samples):\n",
    "    \"\"\"\n",
    "        Classify the given sample using the decision tree.\n",
    "        \n",
    "        Parameters:\n",
    "            tree: decision tree (test, left_tree, right_tree)\n",
    "            samples: a list of Sample objects\n",
    "            \n",
    "        Return:\n",
    "            a list of predicted classes\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "    for s in samples:\n",
    "        curr_tree = tree\n",
    "        \n",
    "        # apply decision trees recursively\n",
    "        while len(curr_tree) == 3:\n",
    "            test = curr_tree[0]\n",
    "            if s.properties[test.property_index] <= test.value:\n",
    "                curr_tree = curr_tree[1]\n",
    "            else:\n",
    "                curr_tree = curr_tree[2]\n",
    "        \n",
    "        # base case - return most common training class for this node\n",
    "        node_classes = curr_tree[1]\n",
    "        predictions.append(max(node_classes, key=node_classes.get))\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hopefully the decision tree will classify the three samples into classes 0 (setosa), 1 (versicolor) and 2 (virginica) respectively.\n",
    "If so, this suggests that the decision tree has found a useful way of classifying types of flower based on the four measurements given, and that this classification works beyond the data that was used to create the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classify_with_decision_tree(dt, test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have seen how to make a decision tree classifier you may be interested to have a look at the scikit-learn documentation about [decision trees](https://scikit-learn.org/stable/modules/tree.html#tree) to find out more.\n",
    "\n",
    "### Overfitting\n",
    "One thing to consider from this example is the problem of overfitting, which is when a learning technique fails to generalise from the data effectively.\n",
    "The outcome is a classifier that works well for the training data but is not reliable otherwise.\n",
    "Overfitting also creates trees which are too large.\n",
    "\n",
    "Notice that all of the leaves in our decision trees contain just a single type of flower. \n",
    "That's good, and is the purpose of the classifier.\n",
    "However, some of them achieve this by containing just one sample! \n",
    "The tests which led to this node only applied to a single sample in the training set, so we have some reason to suspect that they are not good tests in general for recognising this type of flower. \n",
    "\n",
    "Many leaves with a very small number of samples is a sign of possible overfitting.\n",
    "One way to reduce overfitting is to insist on a minimum number of samples associated with each leaf node. \n",
    "You could rewrite the functions above to allow a minimum to be specified and retrain the decision tree. \n",
    "Scikit-learn's decision tree classifier has an optional parameter for a minimum leaf size.\n",
    "\n",
    "Another way of reducing overfitting is to set a maximum depth for the tree. \n",
    "In this case, because the data set was small, the most tests that can be required to classify a sample is 5. \n",
    "With larger datasets decision trees can become very large.\n",
    "We can control this by enforcing that the number of tests between the start of the decision tree and any leaf node does not exceed some given value."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
