{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "810dfdd3",
   "metadata": {},
   "source": [
    "# Scikit-learn\n",
    "\n",
    "The scikit-learn package contains a broad range of open source computational tools for data science and predictive analytics. The scikit-learn package is built on NumPy, SciPy and matplotlib and includes functions and methods for classification, regression, clustering, neural networks and data transformations, as well as many other forms of stistical machine learning. Rather than try to cover lots of different tools, we will focus on a simple example and try to demonstrate how you can go about learning how to use the tools in scikit-learn independently.\n",
    "\n",
    "The scikit-learn package has good documentation, which includes descriptions of the statistics as well as examples of code. In this notebook, we will look at how to fit a regression model to data using the [Linear Regression Example](https://scikit-learn.org/stable/auto_examples/linear_model/plot_ols.html). In linear regression, the response variable (or target value) is assumed to be a linear combination of the explanatory variables (features) plus random, normally distributed noise. If there is only one explanatory variable, then we are trying to fit a straight line to data.\n",
    "\n",
    "The [Linear Regression Example](https://scikit-learn.org/stable/auto_examples/linear_model/plot_ols.html) includes the following code (which should run quickly, although it may take longer the first time you use the scikit-learn pacakge):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fb59328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: \n",
      " [938.23786125]\n",
      "Mean squared error: 2548.07\n",
      "Coefficient of determination: 0.47\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgQAAAGFCAYAAACCBut2AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAfiUlEQVR4nO3df4wcZ33H8c94kthAfOe0oHh9s+2GgAqVIwKlVRMYehtFOC20SZetSq5VmgSJNlRhj4oK2iCatqmqJv1xC2oEoiFAFF+RNmPUKokDlW/ppk5SfqRSUkFN4Ezu1mvSpPHdBRz/mJv+8WR9vl++mb2Znd3Z9+sf5PU8d18h5+Zzz3ee71hBEAQCAAADbUvaBQAAgPQRCAAAAIEAAAAQCAAAgAgEAABABAIAACACAQAAkHRemIsWFxd15MgRbd++XZZlJV0TAACIQRAEWlhY0K5du7Rly7n3AEIFgiNHjiifz8dSHAAA6K6ZmRk5jnPOa0IFgu3bt5/5gkNDQ5uvDAAAJG5+fl75fP7MffxcQgWCdptgaGiIQAAAQJ8J0+7noUIAAEAgAAAABAIAACACAQAAEIEAAACIQAAAAEQgAAAAIhAAAAARCAAAgEJOKgQAAPHzfV+NRkOtVku5XE6u68q27VRqIRAAAJACz/NUqVQ0Ozt75jPHcVStVlUqlbpeDy0DAAC6zPM8lcvlZWFAkprNpsrlsjzP63pNBAIAALrI931VKhUFQbDq79qfjY+Py/f9rtZFIAAAoIsajcaqnYGzBUGgmZkZNRqNLlZFIAAAoKtarVas18WFQAAAQBflcrlYr4sLgQAAgC5yXVeO48iyrDX/3rIs5fN5ua7b1boIBAAAdJFt26pWq5K0KhS0/zwxMdH1eQQEAgAAuqxUKqlWq2lkZGTZ547jqFarpTKHwArWOvewwvz8vIaHhzU3N6ehoaFu1AUAQOYlPakwyv2bSYUAAKTEtm2Njo6mXYYkWgYAAEAEAgAAIAIBAAAQgQAAAIhAAAAARCAAAAAiEAAAABEIAACACAQAAEAEAgAAIAIBAAAQgQAAAIhAAAAARCAAAAAiEAAAABEIAACACAQAAEAEAgAAIAIBAAAQgQAAAIhAAAAARCAAAAAiEAAAABEIAACACAQAAEAEAgAAIAIBAAAQgQAAAIhAAAAARCAAAAAiEAAAABEIAACACAQAAEAEAgAAIAIBAAAQgQAAAIhAAAAARCAAAAAiEAAAABEIAACACAQAAEAEAgAAIAIBAAAQgQAAAIhAAAAARCAAAAAiEAAAABEIAACACAQAAEAEAgAAIAIBAAAQgQAAAIhAAAAARCAAAAAiEAAAABEIAACACAQAAEAEAgAAIAIBAAAQgQAAAIhAAAAARCAAAAAiEAAAABEIAACACAQAAEAEAgAAIAIBAAAQgQAAAIhAAAAARCAAAAAiEAAAABEIAACACAQAAEAEAgAAIAIBAAAQgQAAAIhAAAAARCAAAAAiEAAAABEIAACACAQAAEAEAgAAIAIBAAAQgQAAAIhAAAAARCAAACB1J0+mXQGBAACAVMzOSpdcIlmWtHWr+d/nn0+vHgIBAACSfN9XvV7X5OSk6vW6fN9P5Ps8/LC5+efz0uHDy//uN34jkW8ZCoEAADDwPM9ToVBQsVjU2NiYisWiCoWCPM+L5esvLkp/8icmCPzar61/3ateFcu364gVBEGw0UXz8/MaHh7W3NychoaGulEXAABd4XmeyuWyVt4OLcuSJNVqNZVKpY6+9gsvSNdcI33zm+Guf+456XWv6+hbrSnK/ZsdAgDAwPJ9X5VKZVUYkHTms/Hx8cjtg8ceM7sBr31tuDBwxx1mFyHOMBAVgQAAMLAajYZmZ2fX/fsgCDQzM6NGo7Hh1woC6e/+zgSBK68M9/3rdbPuttvMujSdl+63BwAgPa1Wa9PXvfSS9Fu/Je3fH+577t4t/du/SRdfHO76bmGHAAAwsHK5XMfX/fd/m+OC27eHCwOVinT6tPTUU70XBiQCAQBggLmuK8dxzjxAuJJlWcrn83Jd98xnX/yi2d7fvTvcQKF9+0xbYGJCsu2YCk8AgQAAMLBs21a1WpWkVaGg/eeJiQn5vq0bbjBB4MYbN/66O3dKP/iBCQLXXRdz0QkhEAAABlqpVFKtVtPIyMiyzx3H0d13P6hbby1p61bpvvs2/lq/8zvSyy9LrZaZQthPmEMAAIDMEcRGo6FWq6Xp6d267bbLQq+95x7p5psTLK5DUe7fnDIAAECSZOvWW0f19NMhr7alJ5+ULgufG3oaLQMAwEA7fNg8G3DeeQoVBt79bml+3pwYyEoYkAgEAIABdf/9JgiE7fXfeaeZJvjII+aoYdbQMgAADIwgkN77Xumhh8KvaTSkd74zuZp6BYEAAJB5zz8f/T0BP/yh9DM/k0w9vYiWAQAgs776VdMWCBsG3vpW82xAEAxWGJAIBACQGN/3Va/XNTk5qXq9HvmNeejchz5kgsCePeGu/4d/MCHg29/u7WmCSaJlAAAJ8DxPlUpl2Zv0HMdRtVpVqVRKsbLs+vGPpYsukk6dCr/mqafMCGKwQwAAsfM8T+VyedVrdZvNpsrlsjzPS6mybPrWt8xuwIUXhgsDF10kHT9udgQIA0sIBAAQI9/3ValUtNYQ2PZn4+PjtA9i8Fd/ZYLA298e7vo//mMTAv7v/6Rt25KtrR/RMgCAGDUajVU7A2cLgkAzMzNqNBoaHR3tXmEZceqU9OY3S9//fvg1X/+69K53JVdTVhAIACBGrVYr1utgPPOM9MY3Rlvz4ovSjh2JlJNJtAwAIEa5XC7W6wbdvfeatkDYMPD+95u2QBAQBqJihwAAYuS6rhzHUbPZXPM5Asuy5DiOXNdNobr+EATS1VdLBw6EX/PAAxKHNzaHHQIAiJFt26pWq5LMzf9s7T9PTEzIHtTD7ufwox+Z3YAtW8KHgdlZEyAIA5tHIACAmJVKJdVqNY2MjCz73HEc1Wo15hCs8OCDJgjs3Bnu+iuvlHzfBIEV/xdjE6xgrT2tFebn5zU8PKy5uTkNDQ11oy4A6Hu+76vRaKjVaimXy8l1XXYGznLTTdIXvhD++rvvlm65JbFyMinK/ZtnCAAgIbZtc7RwhYUFKervld/5jvSmNyVTD5bQMgAAJO7xx01bIGwY2LVLOnHCtAUIA91BIAAAJOaTnzRB4Iorwl3/iU+YENBsShdckGxtWI6WAQAgVidPSpdcIh05En7NwYPhQwOSQSAAAMTiu981Y4WjmJ+Xtm9Pph5EQ8sAALApn/mMaQuEDQO/93tL0wQJA72DHQIAQGSLi9I73yk99lj4Nf/6r9J735tcTdgcAgEAILQjR6IPAzp6VLr44mTqQXxoGQAANrRvn2kLhA0DxaLZRQgCwkC/IBAAANZ1/fUmCISdtnzPPSYEHDhg1qF/0DIAACxz7Jh00UXR1hw6FP4VxehN7BAAACRJn/uc+a0+bBi49FIzcyAICANZQCAAgAE3MmKCwAc/GO76O+4wIeCZZ6Tzz0+2NnQPLQMAGECdvGToG9+Q3v72ZOpB+tghAIAB8vDD0V4ydP750ksvmR0BwkC2sUMAAANgzx7pq18Nf/3WrdLLLydXD3oPOwQAkFGnT5vdAMsKHwbuvNPsBhAGBg87BACQMU8+Kb3tbdHWfP/70utfn0w96A/sEABARlQqZjcgShhoTxMkDIAdAgDoY0EgbYn4q90HPyh99rPJ1IP+RSAAgD707LPSz/5stDVPPCH90i8lUw/6Hy0DAOgjn/qUaQtECQMnTpidBMIAzoUdAgDoA0NDZphQWK4r/fu/J1cPsocdAgDoUceOLR0bDBsGvvIVsxtAGEBU7BAAQI/Zty/864bbjh2ThocTKQcDgkAAAD3iHe+QDh4Mf/2OHdKLLyZWDgYMLQMASNHJk0ttgbBh4NOfNm0BwgDixA4BAKTg8celK66ItubZZ6V8Ppl6AHYIAKCLPvABsxsQJQy0pwkSBpAkAgEAJCwIltoCn/98uDUf+YhZ114LJI2WAQAkpJOXDD35pHT55YmUA5wTgQAAYnb99dI//3O0NadOSefxExkp4p8fAMQk6tb+NddIDz+cTC1AVDxDAACb0GwuPR8Q1v795tkAwgB6CYEAADpwxx0mBDhO+DULCyYI7NmTXF1Ap2gZAEAEnTzxHwTx1wHEjR2CDvm+r3q9rsnJSdXrdfm+n3ZJABLy0kvR2wIf/ejSsUGgH7BD0AHP81SpVDQ7O3vmM8dxVK1WVYr6RhIAPevLX5be//5oa555Rrr00mTqAZJEIIjI8zyVy2UFK2J/s9lUuVxWrVYjFAB97uKLpeeei7aGnQD0O1oGEfi+r0qlsioMSDrz2fj4OO0DoA/5/lJbIGwYePe7aQsgOwgEETQajWVtgpWCINDMzIwajUYXqwKwGY89ZkJAlKFAjz5qQsAjjyRXF9BttAwiaLVasV4HID3veY/00EPR1pw+Ldl2MvUAaSMQRJDL5WK9DoDh+74ajYZarZZyuZxc15Wd0J036rHBHTukF19MpBSgp9AyiMB1XTmOI2udnyiWZSmfz8t13S5XBvQvz/NUKBRULBY1NjamYrGoQqEgz/Ni+x6HD0c/Nnj//aYtQBjAoCAQRGDbtqrVqiStCgXtP09MTCT2mw2QNe1TOyufzWmf2tlsKPj4x00IuOSS8Gva0wTHxjb1rYG+YwVrPTK/wvz8vIaHhzU3N6ehoaFu1NXT1ppDkM/nNTExwZFDICTf91UoFNZ9UNeyLDmOo+np6cghm2mCgBHl/s0OQQdKpZIOHz6sqakp7d27V1NTU5qeniYMABHEfWpnbi56W+D22zk2CLTxUGGHbNvW6Oho2mUAfSuuUzv33ivdfHO07/3ss1I+H20NkHUEAgCp2Oypna1bpZMno31PdgKA9dEyAJCKTk7tnDq11BYIGwbe9z7aAlHw4rbBRSAAkIoop3bqdRMCLrgg/Nf/5jdNCKjV4qo4+7pxBBS9i0AAIDWlUkm1Wk0jIyPLPnccR7VaTX//9yVZllQshv+avm+CwC/8QszFZlzSR0DR+zh2CCB1Z08q3Lkzp6uuGo20vlCQpqcTKW0gJHkEFOmKcv/moUIAqbNtW7ncaKSdAEnat0+67rpEShooUY6AcroquwgEAFJ11VXS1FS0NT/5ifSqVyVTzyDixW2QCAQAUsI0wd7Bi9sg8VAhgC5qtaJPE7zrLo4NJo0Xt0EiEADogo99zISAXbvCr2m1TAj46EeTqwsGL26DRCAAkKD2bsCdd4Zf094N2Lkzubqw2kZHQHlXS/Zx7BBArI4fl1796mhr3vY26VvfSqYeRHP2EdBcLifXddkZ6GMcOwTQdffdJ91wQ7Q1Bw9KV1yRTD3oDC9uG1wEAgCb0slpgcXFztYBSA6BAEBkQSBt6eAJJE4KAL2LhwoBhHbwoPnNPkoYuO8+jg0C/YAdAgAbsm2zzR/F8ePStm3J1AMgfgQCAOtimiAwOGgZAFjm0KHo0wQ/9jHaAkC/Y4cAgCTpmmukRx6JtqbVYoAQkBUEAmDA0RYAINEyAAbS3Fz0tkAuR1sAyDICATBAbr/dhIAdO8KvefRREwKOHEmqKgC9gJYBMACYJghgI+wQABnl+9HbAtJSW4AwAAwWAgGQMZ5nbubnRdj/+9zneD4AGHS0DICM6OQ3+pdflrZujb8WAP2HQAD0OY4NAogDLYMB4vu+6vW6JicnVa/X5ft+2iWhQ9/4RvTnA265hbYAgPWxQzAgPM9TpVLR7Ozsmc8cx1G1WlWpVEqxMkRx0UXSsWPR1hw9Kl18cSLlAMgQdggGgOd5KpfLy8KAJDWbTZXLZXmel1JlCKu9GxAlDLR3AwgDAMIgEGSc7/uqVCoK1tgnbn82Pj5O+6AHHT0avS2wezdtAQCdIRBkXKPRWLUzcLYgCDQzM6NGo9HFqnAuv/3bJgTkcuHXtKcJPvVUcnUByDaeIci4VqsV63VIDqcFAKSJHYKMy4X8NTPsdYjXyZObmyYIAHEhEGSc67pyHEfWOnccy7KUz+flum6XKxts1aoJAVGGAn3mMwQBAMmhZZBxtm2rWq2qXC7LsqxlDxe2Q8LExIRs206rxIHSSVvg1KloY4gBoBPsEAyAUqmkWq2mkZGRZZ87jqNarcYcgi7YTFuAMACgG6xgrfNoK8zPz2t4eFhzc3MaGhrqRl1IgO/7ajQaarVayuVycl2XnYEETU1JV10Vbc2NN0r33ptIOQAGUJT7N797DBDbtjU6Opp2GZnXSVvgf/9Xeu1r468FAMIiEAAx4dgggH7GMwTAJvzwh9GfD3AcTgsA6D0EAqADV19tQkChEH7Nk0+aEDAzk1hZANAxWgZABLQFAGQVOwTABn7yE6YJAsg+AgGwjr/4CxMCXvOa8Gv27iUIAOhPtAyAFTppC/i+tIV4DaCPEQgAmd/oO7mhsxMAICv4nQYD7WtfMzsCUcLARz5CWwBA9rBDgIE0PCzNz0dbMzcnMbkbQFYRCDBQODYIAGujZYDM+8EPoh8bfOtbaQsAGCwEAmTWddeZEHDppeHXfPe7JgR8+9uJlQUAPYmWATKnk7bA3r2TyuVyesMbXEm8EhrA4GGHAJmwsBC9LXDhhSflOHlJlsbGxlQsFlUoFOR5XmJ1AkCvIhCgr/31X5sQEOXp/wMHpAce8PTjH2/T7Ozssr9rNpsql8uEAgADxwqCjR+bmp+f1/DwsObm5jTEuSv0gE7aAouLZp3v+yoUCqvCwNLXtuQ4jqanp2XbtA8A9K8o9292CNA32jf0Tl8y1F7XaDTWDQPm+kAzMzNqNBqbqBYA+guBAD3vwQfNzTzKL+v/+I/rHxtstVqhvkbY6wAgCzhlgJ7VSVvg+HFp27ZzX5PL5UJ9rbDXAUAWsEOAnrOZtsBGYUCSXNeV4ziy1vkmlmUpn8/Ldd1oRQBAHyMQoCd85zvRg8DNN3c2TdC2bVWrVUlaFQraf56YmOCBQgADhUCAVP3Kr5gQ8PM/H35Ns2lCwD33dP59S6WSarWaRkZGln3uOI5qtZpKpVLnXxwA+hDHDpGKXnnJkO/7ajQaarVayuVycl2XnQEAmRHl/s1DheiaF1+Ufuqnoq15wxuk730vmXok0z4YHR1N7hsAQJ+gZYDE/emfmh2BKGHgiSfMjkCSYQAAsIQdAiSmV9oCAICNsUOAWJ0+vbljgwCAdBAIEIsvf9mEgPPPD7/mS18iCABAr6BlgMjOfjJ/bOz6yOtPnowWHAAAySMQIBLP81SpVDQ7OxN5LTsBANC7aBkgtL/92wN63/tKkcLAH/0RbQEA6AfsEGBDl10mPf20JF0Ves3zz0s//dOJlQQAiBk7BFhX+7SACQPhTE3VFQSEAQDoNwQCLPOjH3VybPBxSZYkS61WK5nCAACJIhBAkvShD5kQsHNnlFW7ZYLAFWc+yeVyMVcGAOgGniEYcJ1MEzQhYOXXseQ4jlzX3XRNAIDuY4dgAJ061dk0wQce8GRZW2StWNj+88TEBG8KBIA+RSAYIPW6CQEXXBB+zb59S8cGS6WSarWaRkZGll3jOI5qtZpKpVK8BQMAusYKgo1PiEd5nzJ6j+tKjz4abY3vS1vWiYtnTyrM5XJyXZedAQDoQVHu3zxDkFFBsP4NfaN1G7FtW6Ojo9G/OPoWIRDIPloGGXPokGkLRAkDf/7nTBPE+jzPU6FQULFY1NjYmIrFogqFgjzPS7s0ADEiEGTEhz9sgsDP/Vz4NQsLJgR88pPJ1YX+5nmeyuWyZmdnl33ebDZVLpcJBUCG8AxBn+vk2CA7AQjD930VCoVVYaCtfdR0enqa9gHQo6Lcv9kh6EMvvBD92OBdd9EWQDSNRmPdMCBJQRBoZmZGjUaji1UBSAoPFfaRu++W/vAPo61ptaJOHwSMsGOoGVcNZAOBoA/QFkAawo6hZlw1kA20DHrUiRPR2wI33khbAPFxXVeO46yaTNlmWZby+TzjqoGMIBD0mP37TQjYti38mqeeMiHg3nuTqwuDx7ZtVatVSWJcNTAACAQ94vLLTRD41V8Nv2Zx0QSB3bsTKyvzfN9XvV7X5OSk6vW6fN9Pu6SewrhqYHBw7DBFnUwTfMtbpP/6r0TKGTie56lSqSx7kt5xHFWrVW50KzCpEOhPUe7fBIIUPP20dNll0dbs3y/t2ZNMPYOoPXBn5T//9lY4v/0CyALmEPSom24ybYEoYeDECbOTQBiIj+/7qlQqq8KApDOfjY+P0z4AMFA4dtgFHBvsLVEG7vASJwCDgh2ChBw9Gv3Y4N13c2ywGxi4AwCrEQhidtddJgREmdXywgsmBNxyS3J1YQkDdwBgNVoGMaEt0D/aA3eazeaazxG0X9rDwB0Ag4Qdgk04fjx6W+DWW2kLpI2BOwCwGoGgA489ZkLAq18dfs2hQyYEfOpTydWF8Bi4AwDLMYcggptukr7whWhrFhc7ayegOxi4AyDLoty/eYZgA51ME3zXu6Svfz2ZehAv27Y5WggAomWwru99z/xmHyUM1OsmQBAGAAD9hh2CFR56SHrPe6KtOX1aGtRdZrbcASAb2CF4xQc+YHYEwoaBa69dOi0wqPc/z/NUKBRULBY1NjamYrGoQqEgz/PSLg0AENFA7xAsLEhRn5H82tekq69Opp5+st7LgZrNpsrlMk/qA0CfGcgdgieeMLsBUcLASy+Z3QDCAC8HAoAsGqhAcPvtJgj88i+Hu/6225baAq95TaKldZ3v+6rX65qcnFS9Xo90847yciAAQH/IfMvg5Enp0kulc9y/VvmP/5CuvDK5mtLmeZ4qlcqym7rjOKpWq6G2+Xk5EABkT2Z3CP7nf8xuwNat4cPA3JzZDch6GCiXy6t+w2/3/sM8EMjLgQAgezIXCD77WRME3vSmcNffcMNSWyDrQxjj6v23Xw608j0AbZZlKZ/P83IgAOgjmQgEi4vSO95hgsAf/EG4Nf/yLyYEfPGLydbWS+Lq/fNyIADInr4OBEeOmBBg29LBg+HWtFomCPz6rydbWy+Ks/fPy4EAIFv68qHCr3xF+s3fDH/96Kh04AAvGYq7918qlXTttdcyqRAAMqCv3nb4u78r3X9/+Ov/6Z/MBEIYvu+rUCio2Wyu+RyBZVlyHEfT09Pc1AEgAzL1tsO5OWnHjmhrDh2S3vjGRMrpa+3ef7lclmVZy0IBvX8AGGw9+wzBo4+aLf6wYeD1rzczB4KAMHAu9P4BAGvpuZbBxz8u/c3fhL/+L/9S+sQnkqsnq3hLIQBkX9+1DE6ckEZGpBdeCL/mP/9T+sVfTK6mrLNtW6Ojo2mXAQDoEakGgqNHpTe/WTp2LNz1tm2uvfDCJKsCAGDwpPYMQaslveUt4cLA7/++eTbg9GnCAAAASUhth8DzpOeeO/c1+/dLe/Z0px4AAAZZaoHgXLNvnntOet3rulcLAACDLrWWwbXXSn/2Z9Lll5s/f/jD5p0EQUAYAACg23ru2CEAAIhHlPt3zw4mAgAA3UMgAAAABAIAAEAgAAAAIhAAAAARCAAAgHrk5Ua9hjcBAgAGDYFgBc/zVKlUNDs7e+Yzx3FUrVZVKpVSrAwAgOTQMjiL53kql8vLwoAkNZtNlctleZ6XUmUAACSLQPAK3/dVqVS01uDG9mfj4+Pyfb/bpQEAkDgCwSsajcaqnYGzBUGgmZkZNRqNLlYFAEB3EAhe0Wq1Yr0OAIB+QiB4Re5c72Pu4DoAAPoJpwxe4bquHMdRs9lc8zkCy7LkOI5c102hOiAeHKkFsB52CF5h27aq1aokc/M/W/vPExMT/PAMyfd91et1TU5Oql6v8zBmD/A8T4VCQcViUWNjYyoWiyoUCpyeASCJQLBMqVRSrVbTyMjIss8dx1GtVmMOQUjceHoPR2oBbMQK1tofX2F+fl7Dw8Oam5vT0NBQN+pKFduqnWvfeFb+s2rvshCsus/3fRUKhXVP0bTbYdPT0/w7BzImyv2bQIDYJH3jIah1pl6vq1gsbnjd1NSURkdHky8IQNdEuX/TMkBskpzlQBuicxypBRAGgQCxSerGQ/97czhSCyAMAgFik8SNh5HSm9c+Urvy9EybZVnK5/McqQUGHIEAsUnixsNI6c3jSC2AMAgEiE0SNx763/HgSC2AjRAIEKu4bzz0v+NTKpV0+PBhTU1Nae/evZqamtL09DRhAIAkjh0iIXEdEWwfZdxopDRn6AFgtSj3b95lgETYth3LmfZ2G6JcLsuyrGWhgP43AMSnZ1oGzL7Heuh/A0DyeqJl4HmeKpXKsqfJHcdRtVrlhz3OYFIhAETTV6OLmX0PAEAy+mZ0MUNnAADoDakGAobOAADQG1INBAydAQCgN6QaCBg6AwBAb0g1EPDSFQAAekOqgYCXrgAA0BtSH0zE0BkAANKX+hyCNobOANHx3w2Ac+mbdxnwwwzoHBM+AcQptZaB53kqFAoqFosaGxtTsVhUoVCQ53lplQT0jfaEz5VzPJrNpsrlMv8dAYgslZYB44qBzrVfCb3eUC9eCQ2gradHFzOuGNgcJnwCSELXAwE/zIDNYcIngCR0PRDwwwzYHCZ8AkhC1wMBP8yAzWHCJ4AkdD0Q8MMM2BwmfAJIQtcDAT/MgM1jwieAuKU2qXCtoSr5fF4TExP8MANCYrgXgHOJcv9OdXQxP8wAAEhO34wutm1bo6OjaZYAAADUA287BAAA6SMQAAAAAgEAACAQAAAAEQgAAIAIBAAAQAQCAAAgAgEAABCBAAAAKOSkwvZ04/n5+USLAQAA8Wnft0O8pSBcIFhYWJBkXj4EAAD6y8LCgoaHh895TaiXGy0uLurIkSPavn37qlcWAwCA3hQEgRYWFrRr1y5t2XLupwRCBQIAAJBtPFQIAAAIBAAAgEAAAABEIAAAACIQAAAAEQgAAIAIBAAAQNL/A5L4V5PJ3rqRAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Code source: Jaques Grobler\n",
    "# License: BSD 3 clause\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load the diabetes dataset\n",
    "diabetes_X, diabetes_y = datasets.load_diabetes(return_X_y=True)\n",
    "\n",
    "# Use only one feature\n",
    "diabetes_X = diabetes_X[:, np.newaxis, 2]\n",
    "\n",
    "# Split the data into training/testing sets\n",
    "diabetes_X_train = diabetes_X[:-20]\n",
    "diabetes_X_test = diabetes_X[-20:]\n",
    "\n",
    "# Split the targets into training/testing sets\n",
    "diabetes_y_train = diabetes_y[:-20]\n",
    "diabetes_y_test = diabetes_y[-20:]\n",
    "\n",
    "# Create linear regression object\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr.fit(diabetes_X_train, diabetes_y_train)\n",
    "\n",
    "# Make predictions using the testing set\n",
    "diabetes_y_pred = regr.predict(diabetes_X_test)\n",
    "\n",
    "# The coefficients\n",
    "print(\"Coefficients: \\n\", regr.coef_)\n",
    "# The mean squared error\n",
    "print(\"Mean squared error: %.2f\" % mean_squared_error(diabetes_y_test, diabetes_y_pred))\n",
    "# The coefficient of determination: 1 is perfect prediction\n",
    "print(\"Coefficient of determination: %.2f\" % r2_score(diabetes_y_test, diabetes_y_pred))\n",
    "\n",
    "# Plot outputs\n",
    "plt.scatter(diabetes_X_test, diabetes_y_test, color=\"black\")\n",
    "plt.plot(diabetes_X_test, diabetes_y_pred, color=\"blue\", linewidth=3)\n",
    "\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760787d7",
   "metadata": {},
   "source": [
    "The output prints the coefficient value, a measure of error, the $R^2$ metric and an illustration of the fit to the data. That was pretty easy! **But are we now able to use the scikit-learn package to do regression?** Probably we need to do a bit more work before we will feel confident applying it in a new setting. \n",
    "\n",
    "In this notebook, it is assumed that you **do not** have a detailed understanding of regression, and while some explanation will be provided, it will not be enough to enable you to apply regression effectively to other situations. Our focus will be how to use the programs, how to find out about there settings, and what effects these have, rather than how the statistical methods (regression in this case) work.\n",
    "\n",
    "So let's dig into this example in a little more detail.\n",
    "\n",
    "The first lines of code are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb0ef58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a31235",
   "metadata": {},
   "source": [
    "These import a variety of tools from matplotlib, NumPy and scikit-learn. Usually we wouldn't know in advance what we would need, so we might start with nothing, or perhaps matplotlib and NumPy, then add packages and functions as we require them. The next line of code uses the `datasets` function from `sklearn`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0635ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the diabetes dataset\n",
    "diabetes_X, diabetes_y = datasets.load_diabetes(return_X_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89185533",
   "metadata": {},
   "source": [
    "The [Linear Regression Example](https://scikit-learn.org/stable/auto_examples/linear_model/plot_ols.html) helpfully includes a [link to the documentation](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_diabetes.html#sklearn.datasets.load_diabetes) for the `load_diabetes` method. **Have a look at this documentation.** It describes what the `return_X_y` parameter does, as well as what the other parameters are, what they do and what is returned.\n",
    "\n",
    "Note that this documentation is really helpful. It would be really hard to work out how the function works without it. Unfortunately not all documentation is this good, and often when you start using a new package, you may have to spend time searching online through documentation, tutorials and discussion forums to find out how it works. Similarly, you will also benefit from documenting your own work, by writing descriptions of what you've done, what resources you used and where to find them. This is especially important if you share your code online.\n",
    "\n",
    "Since the `return_X_y` parameter is `True`, the `diabetes_X` variable is the (explanatory) data and the `diabetes_y` variable is the target (response). Let's have a look at these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "642a57a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.03807591,  0.05068012,  0.06169621, ..., -0.00259226,\n",
       "         0.01990749, -0.01764613],\n",
       "       [-0.00188202, -0.04464164, -0.05147406, ..., -0.03949338,\n",
       "        -0.06833155, -0.09220405],\n",
       "       [ 0.08529891,  0.05068012,  0.04445121, ..., -0.00259226,\n",
       "         0.00286131, -0.02593034],\n",
       "       ...,\n",
       "       [ 0.04170844,  0.05068012, -0.01590626, ..., -0.01107952,\n",
       "        -0.04688253,  0.01549073],\n",
       "       [-0.04547248, -0.04464164,  0.03906215, ...,  0.02655962,\n",
       "         0.04452873, -0.02593034],\n",
       "       [-0.04547248, -0.04464164, -0.0730303 , ..., -0.03949338,\n",
       "        -0.00422151,  0.00306441]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c45fbaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(442, 10)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c99f3918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([151.,  75., 141., 206., 135.,  97., 138.,  63., 110., 310., 101.,\n",
       "        69., 179., 185., 118., 171., 166., 144.,  97., 168.,  68.,  49.,\n",
       "        68., 245., 184., 202., 137.,  85., 131., 283., 129.,  59., 341.,\n",
       "        87.,  65., 102., 265., 276., 252.,  90., 100.,  55.,  61.,  92.,\n",
       "       259.,  53., 190., 142.,  75., 142., 155., 225.,  59., 104., 182.,\n",
       "       128.,  52.,  37., 170., 170.,  61., 144.,  52., 128.,  71., 163.,\n",
       "       150.,  97., 160., 178.,  48., 270., 202., 111.,  85.,  42., 170.,\n",
       "       200., 252., 113., 143.,  51.,  52., 210.,  65., 141.,  55., 134.,\n",
       "        42., 111.,  98., 164.,  48.,  96.,  90., 162., 150., 279.,  92.,\n",
       "        83., 128., 102., 302., 198.,  95.,  53., 134., 144., 232.,  81.,\n",
       "       104.,  59., 246., 297., 258., 229., 275., 281., 179., 200., 200.,\n",
       "       173., 180.,  84., 121., 161.,  99., 109., 115., 268., 274., 158.,\n",
       "       107.,  83., 103., 272.,  85., 280., 336., 281., 118., 317., 235.,\n",
       "        60., 174., 259., 178., 128.,  96., 126., 288.,  88., 292.,  71.,\n",
       "       197., 186.,  25.,  84.,  96., 195.,  53., 217., 172., 131., 214.,\n",
       "        59.,  70., 220., 268., 152.,  47.,  74., 295., 101., 151., 127.,\n",
       "       237., 225.,  81., 151., 107.,  64., 138., 185., 265., 101., 137.,\n",
       "       143., 141.,  79., 292., 178.,  91., 116.,  86., 122.,  72., 129.,\n",
       "       142.,  90., 158.,  39., 196., 222., 277.,  99., 196., 202., 155.,\n",
       "        77., 191.,  70.,  73.,  49.,  65., 263., 248., 296., 214., 185.,\n",
       "        78.,  93., 252., 150.,  77., 208.,  77., 108., 160.,  53., 220.,\n",
       "       154., 259.,  90., 246., 124.,  67.,  72., 257., 262., 275., 177.,\n",
       "        71.,  47., 187., 125.,  78.,  51., 258., 215., 303., 243.,  91.,\n",
       "       150., 310., 153., 346.,  63.,  89.,  50.,  39., 103., 308., 116.,\n",
       "       145.,  74.,  45., 115., 264.,  87., 202., 127., 182., 241.,  66.,\n",
       "        94., 283.,  64., 102., 200., 265.,  94., 230., 181., 156., 233.,\n",
       "        60., 219.,  80.,  68., 332., 248.,  84., 200.,  55.,  85.,  89.,\n",
       "        31., 129.,  83., 275.,  65., 198., 236., 253., 124.,  44., 172.,\n",
       "       114., 142., 109., 180., 144., 163., 147.,  97., 220., 190., 109.,\n",
       "       191., 122., 230., 242., 248., 249., 192., 131., 237.,  78., 135.,\n",
       "       244., 199., 270., 164.,  72.,  96., 306.,  91., 214.,  95., 216.,\n",
       "       263., 178., 113., 200., 139., 139.,  88., 148.,  88., 243.,  71.,\n",
       "        77., 109., 272.,  60.,  54., 221.,  90., 311., 281., 182., 321.,\n",
       "        58., 262., 206., 233., 242., 123., 167.,  63., 197.,  71., 168.,\n",
       "       140., 217., 121., 235., 245.,  40.,  52., 104., 132.,  88.,  69.,\n",
       "       219.,  72., 201., 110.,  51., 277.,  63., 118.,  69., 273., 258.,\n",
       "        43., 198., 242., 232., 175.,  93., 168., 275., 293., 281.,  72.,\n",
       "       140., 189., 181., 209., 136., 261., 113., 131., 174., 257.,  55.,\n",
       "        84.,  42., 146., 212., 233.,  91., 111., 152., 120.,  67., 310.,\n",
       "        94., 183.,  66., 173.,  72.,  49.,  64.,  48., 178., 104., 132.,\n",
       "       220.,  57.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4198d37f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(442,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc7f2ca",
   "metadata": {},
   "source": [
    "Both variables have 442 rows, but `diabetes_X` has 10 columns, whereas `diabetes_y` is one-dimensional; `diabetes_X` seems to contain positive and negative decimals, whereas `diabetes_y` seems to be positive integers.\n",
    "\n",
    "Some natural questions we might ask are where does this data come from? What do the values refer to? Has any scaling been applied to the data? How could we visulalise the data? What might we be able to do with the data?\n",
    "\n",
    "The scikit-learn documentation has [descriptions of the data sets that come with the package](https://scikit-learn.org/stable/datasets/toy_dataset.html#diabetes-dataset), which also has a [link to the diabetes source data](https://www4.stat.ncsu.edu/~boos/var.select/diabetes.html) and [further information](https://hastie.su.domains/Papers/LARS/LeastAngle_2002.pdf) about the diabetes data. The [further information](https://hastie.su.domains/Papers/LARS/LeastAngle_2002.pdf) is a paper that uses the data to demonstrate a statistical method called \"Least Angle Regression\" (LARS). It is worth having a look at the paper, but what you should realise is that it focuses on the LARS method and has very little description about the data, its source and what we might infer from analysing it. However, the web page with the [source data](https://www4.stat.ncsu.edu/~boos/var.select/diabetes.html) does include the [raw data](https://www4.stat.ncsu.edu/~boos/var.select/diabetes.tab.txt). \n",
    "\n",
    "### Exercise 1\n",
    "Experiment with the parameters for `load_diabetes`. What format does the data take when there no parameters are given? Can you get the data as a pandas dataframe? Check that the [raw data](https://www4.stat.ncsu.edu/~boos/var.select/diabetes.tab.txt) online matches up with the data that you get when we call the `load_diabetes` method with the `scaled` parameter set to `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b38c7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ba529b85",
   "metadata": {},
   "source": [
    "The `diabetes_X` variable has 10 columns, and the [scikit-learn documentation](https://scikit-learn.org/stable/datasets/toy_dataset.html#diabetes-dataset) lists these as\n",
    "* age - age in years\n",
    "* sex - this is represented as either 1 or 2\n",
    "* bmi - body mass index\n",
    "* bp - average blood pressure\n",
    "* s1 tc - total serum cholesterol\n",
    "* s2 ldl - low-density lipoproteins\n",
    "* s3 hdl - high-density lipoproteins\n",
    "* s4 tch - total cholesterol / HDL\n",
    "* s5 ltg - possibly log of serum triglycerides level\n",
    "* s6 glu - blood sugar level\n",
    "\n",
    "We might assume that this order corresponds to the order of the columns in the data, but it's a good thing to check. To do this, we might look at the [raw data](https://www4.stat.ncsu.edu/~boos/var.select/diabetes.tab.txt) for example. You'd be surprised how often mistakes like incorrectly labelling data occur, and how much time it can take to find them.\n",
    "\n",
    "Let's continue to work through the example code. The next line is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "962b8c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use only one feature\n",
    "diabetes_X = diabetes_X[:, np.newaxis, 2]  # equivalent to diabetes_X[:, 2].reshape(-1, 1)\n",
    "\n",
    "#TRY\n",
    "#diabetes_X[:, 2].shape    # (442,) â†’ 1D array\n",
    "#diabetes_X[:, np.newaxis, 2].shape    # (442, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae73a747",
   "metadata": {},
   "source": [
    "This line reasigns `diabetes_X` to its third column and the `np.newaxis` attribute makes the resulting array two-dimensional:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa43ea5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(442, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes_X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9b3ab2",
   "metadata": {},
   "source": [
    "i.e. it has 442 rows and 1 column. Compare this to if we had just taken the third column of `diabetes_X`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bbeb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_X, diabetes_y = datasets.load_diabetes(return_X_y=True)\n",
    "diabetes_X[:,2].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ccf384",
   "metadata": {},
   "source": [
    "The reason we need `diabetes_X` to be two-dimensional is because the `fit` method that uses this data expects two-dimensional arrays and will produce an error if we give it data without a second dimension.\n",
    "\n",
    "We can also make `diabetes_X` two-dimensional by using `np.newaxis` in the third position (which may seem more intutitive):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df742eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_X=diabetes_X[:,2,np.newaxis]\n",
    "diabetes_X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2fa059",
   "metadata": {},
   "source": [
    "The next lines of code divide the data and target up into training and testing sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc8db90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training/testing sets\n",
    "diabetes_X_train = diabetes_X[:-20]\n",
    "diabetes_X_test = diabetes_X[-20:]\n",
    "\n",
    "# Split the targets into training/testing sets\n",
    "diabetes_y_train = diabetes_y[:-20]\n",
    "diabetes_y_test = diabetes_y[-20:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3649f600",
   "metadata": {},
   "source": [
    "Here 20 data points have been used as testing data. The training set will be used to fit the model, then the training set will be used to evaluate how good the model fits.\n",
    "\n",
    "The next line of code creates an instance of the `linear_model` class, which has the methods needed to fit the data using a linear model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8619e13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create linear regression object\n",
    "regr = linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83b9782",
   "metadata": {},
   "source": [
    "Again, the [Linear Regression Example](https://scikit-learn.org/stable/auto_examples/linear_model/plot_ols.html) has a link to the [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression) for the `linear_model` class where you can find out about the parameters that can be used, as well as the attributes and methods of the class. Note that many of the attributes only appear once the model has been fitted.\n",
    "\n",
    "The next line fits the linear model to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e1bae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model using the training sets\n",
    "regr.fit(diabetes_X_train, diabetes_y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241ae5b0",
   "metadata": {},
   "source": [
    "You can see the attributes and methods asigned to `regr` by typing `regr.` and pressing the auto-complete button tab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e13a57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a . after regr and press tab to see the attributes and methods\n",
    "regr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cbeb4c5",
   "metadata": {},
   "source": [
    "Fitting the model to the data has caused a lot of things to happen that we only see the result of, which is why it's important to know the theory that underpins linear regression (which is covered elsewhere in the Data Science (Statistics) programme). However, the package may also make decisions about the best numerical methods to use in a given situation. You may have to find out about these as well if you get errors when you try to apply the method to your data, or if the method takes too long. You may be able to determine this from the documentation, but with open source software, you may have to go to the source code.\n",
    "\n",
    "The next line of code uses the fitted model to predict the target values for the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e30821b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions using the testing set\n",
    "diabetes_y_pred = regr.predict(diabetes_X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a199e1",
   "metadata": {},
   "source": [
    "The linear model that we have fitted is the straight line through the data that minimises the sum of squared errors. Predictions are then the corresponding points along this line - we will visualise this shortly.\n",
    "\n",
    "The next line prints out the regression coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4211e0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The coefficients\n",
    "print(\"Coefficients: \\n\", regr.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea98a5e",
   "metadata": {},
   "source": [
    "This is the slope of the line. It would also be useful to know the intercept:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc71ef18",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Intercept: \\n\",regr.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b8b8b9",
   "metadata": {},
   "source": [
    "The next two lines compute the mean squared error between the testing set and the model predictions as well as the $R^2$ value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f3cd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The mean squared error\n",
    "print(\"Mean squared error: %.2f\" % mean_squared_error(diabetes_y_test, diabetes_y_pred))\n",
    "# The coefficient of determination: 1 is perfect prediction\n",
    "print(\"Coefficient of determination: %.2f\" % r2_score(diabetes_y_test, diabetes_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3af0f76",
   "metadata": {},
   "source": [
    "The smaller the mean squared error the better the prediction, but is this value small or large? The mean squared error is computed by taking the mean of the square of the difference between points in the testing set and the corresponding predictions. One comparison we could use is with the mean squared error between the training data and the corresponding predictions. Computing this we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae81c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_y_pred_train = regr.predict(diabetes_X_train)\n",
    "print(f\"Mean squared error of training data: {mean_squared_error(diabetes_y_train, diabetes_y_pred_train):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c657e5f",
   "metadata": {},
   "source": [
    "So the testing error is smaller than this, which may seem like a good thing. However, if our linear model of the data is accurate then really we are just lucky that our (relatively small) training set has smaller error. If it was much different then it might be good to question why - how was the training set chosen? Ideally this would be a random sample of the data. Also, this being a mean squared error, larger errors contribute significantly more to the value of the error metric. Therefore we might also consider other error metrics.\n",
    "\n",
    "We saw above that the $R^2$ was 0.47. The $R^2$, or coefficient of determination, measures how much of the variation in the target variable is predicted by the variation in the data. The $R^2$ varies between 0 and 1, where a perfect fit results in an $R^2$ close to 1, and an $R^2$ equal to Zero suggests that the fit is no better estimate than the average of the data. Here 47% of the variation in the target variable is predicted by the variation in the data, so this isn't a particularly good fit. This will become clearer from plotting the results, as the next lines in the example do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6bf0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot outputs\n",
    "plt.scatter(diabetes_X_test, diabetes_y_test, color=\"black\")\n",
    "plt.plot(diabetes_X_test, diabetes_y_pred, color=\"blue\", linewidth=3)\n",
    "\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0c3511",
   "metadata": {},
   "source": [
    "In this plot, the points correspond to the testing data and the line is the model. Note that the predictions have been used to draw this line. In principle we could have used the intercept and coefficient to plot this line, but using the predictions proves convenient here.\n",
    "\n",
    "Given that this plot was used as an example of how to do linear regression in scikit-learn, it perhaps isn't important to include values on the axes or labels. However, in this form it doesn't allow us to infer much from the regression, so there is certainly room to improve how informative this figure is. Below is an alternative plot, and you may consider how this could also be improved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac2816d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure parameters\n",
    "# lwt=2 # linewidth\n",
    "ms=20 # marker size\n",
    "\n",
    "# Better to use unscaled bmi.\n",
    "diabetes_X_unscaled, _ = datasets.load_diabetes(return_X_y=True,scaled=False)\n",
    "diabetes_X_unscaled=diabetes_X_unscaled[:,2]\n",
    "diabetes_X_unscaled_train=diabetes_X_unscaled[:-20]\n",
    "diabetes_X_unscaled_test=diabetes_X_unscaled[-20:]\n",
    "\n",
    "plt.scatter(diabetes_X_unscaled_train, diabetes_y_train, s=ms,color=0.9*np.ones(3),zorder=0)\n",
    "for i in range(len(diabetes_X_unscaled_test)):\n",
    "    plt.plot([diabetes_X_unscaled_test[i],diabetes_X_unscaled_test[i]],\n",
    "             [diabetes_y_pred[i],diabetes_y_test[i]],color=\"red\",zorder=1,linewidth=1)\n",
    "plt.plot(diabetes_X_unscaled_train, diabetes_y_pred_train, color=\"blue\", linewidth=2,zorder=2)\n",
    "plt.scatter(diabetes_X_unscaled_test, diabetes_y_test, s=ms, color=\"black\",zorder=3)\n",
    "\n",
    "plt.xlabel('Body Mass Index')\n",
    "plt.ylabel('Disease propagation measure');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622008fc",
   "metadata": {},
   "source": [
    "In this figure we can see the training data in light gray markers, as well as the testing data in black markers. The blue line indicates the linear model fit and the red lines indicate the errors (i.e. the difference between the data and the predicted values along the line of best fit). The explanatory variable is body mass index (BMI), and the unscaled values have been plotted. It's not clear exactly what the target variable is, but the reference paper refers to this as \"a measure of disease propagation one year after baseline\".\n",
    "\n",
    "From this figure it should be clear that we might use our linear regression to ask whether BMI could be used to predict disease propagation. The results suggest that BMI is positively correlated with the measure of disease propagation, but the relatively small $R^2$ value suggests that BMI alone is not a strong predictor of disease propagation. In this figure we can see more clearly that the testing data does not represent the variation seen in the training data, and hence why the mean squared error was relatively small."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a557e6e",
   "metadata": {},
   "source": [
    "### Exercise 1 solution\n",
    "\n",
    "First load up the data with no parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62827597",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = datasets.load_diabetes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5ad4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130f9611",
   "metadata": {},
   "source": [
    "With no parameters, a dictionary-like object called a \"[bunch](https://scikit-learn.org/stable/modules/generated/sklearn.utils.Bunch.html#sklearn.utils.Bunch)\" is returned. This includes, the data, the target, feature names, a description of the data, as well as the data file names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb66a27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = datasets.load_diabetes(as_frame=True)\n",
    "data['frame']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e6e00b",
   "metadata": {},
   "source": [
    "If we want to view the data as a pandas dataframe, we should import pandas first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d71814",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b1cec7",
   "metadata": {},
   "source": [
    "When `as_frame=True`, a bunch is still returned, but the pandas data frame can be accessed via the `frame` attribute.\n",
    "\n",
    "Now let's set remove the scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e038b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = datasets.load_diabetes(as_frame=True,scaled=False)\n",
    "data['frame']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83434f7",
   "metadata": {},
   "source": [
    "The numbers here seem to match up with the [raw data](https://www4.stat.ncsu.edu/~boos/var.select/diabetes.tab.txt)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107e7138",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bbe821",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5948b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
